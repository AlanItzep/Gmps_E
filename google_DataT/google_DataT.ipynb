{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import time, re\n",
    "from tqdm import tqdm_notebook as tqdmn\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException, ElementClickInterceptedException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "# BREVE INFORMACIÓN IMPORTANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación de cuanto tiempo y como fue el proceso de scraping real\n",
    "Esta parte del proceso ha tardado 4 días aproximadamente en realizarse (este intervalo de tiempo se estima sin tener en cuenta el tiempo que se perdía cuando ocurrían las interrupciones abruptas).\n",
    "Factor importante para continuar es que los registros que se consultaron fueron los aproximadamente ochenta mil registros que proporciono Eixos al inicio de este análisis.\n",
    "Teniendo en cuenta que serian ochenta mil consultas, que el proceso de scraping necesitaba mucho tiempo de procesamiento y también de que el ordenador donde trabajaba no lo quería dejar de utilizar para dedicarlo a esta fase, por eso se optó por utilizar otro ordenador. Un ordenador viejo que se tenía guardado. A este ordenador se le instaló Ubuntu 18 y la distribución de Anaconda. La idea fue dedicar directamente este ordenador a que estuviera consultando este dataset que facilito Eixos.  \n",
    "Y así fue, para esto también se tuvo que instalar el ChromeDriver para Linux, la librería Selenium, Folium y definitivamente el navegador Google Chrome en su versión 81. En cuanto a esto, se debe mencionar que toda la configuración en Linux se realizó por línea de comandos. Pero sin contratiempos, se fueron desarrollando bien las consultas.  \n",
    "Cuando se refiere a la configuración por terminal se toma en cuenta el cambiar el Google Chrome de versión 81 a versión 80, cambiar la versión de Selenium en Anaconda, asignar al path el ChromeDriver o ir probando instalar distintas versiones de ChromeDriver, entre otras configuraciones que se realizaron en este ordenador que se dedicó a esta tarea.  \n",
    "Esto hasta que después de consultar 25 mil registros un error no dejo seguir haciendo consultas. Este suceso se siguió repitiendo hasta el final de las consultas por lo que muchas veces las consultas fueron paradas abruptamente y por esta razón hay 19 data sets donde el primer número en el nombre de cada fichero CSV indica hasta el registro al que se consultó y el segundo número indica cuantos registros se obtuvieron satisfactoriamente y cuantos se quedaron guardados en dicho fichero.  \n",
    "El célebre error fue este:\n",
    "\n",
    "***TimeoutException: Message: timeout: Timed out receiving message from renderer: 16,270(Session info: headless chrome=81.0.4044.122)***\n",
    "\n",
    "Este problema recurrente se consultó en foros como StackOverflow y si que aparecía y se aplicaron las medidas que se sugerían, y si que aliviaban las interrupciones del código de consulta pero al final siempre volvía a ocurrir. Una hipótesis es que este problema se debía a que al haber realizado muchas consultas desde el ordenador dedicado a esta tarea, de alguna manera su IP fue baneada o puesta en una Black list. Esta hipótesis tomaba fuerza pues al principio las consultas y los registros encontrados satisfactoriamente fueron en gran manera exitosos, pero después se volvió lento y constantemente interrumpido. Puede ser que esto se haya debido a que al principio no se ha utilizado ningún tipo de VPN. Luego si que se hizo el cambio y configurando en la terminal el servicio HideMyVPN el proceso si que avanzo mejor.  \n",
    "Finalmente este proceso tomo varios días, aproximadamente dos semanas, entre las interrupciones, la consecución del código definitivo que retornara los parámetros necesarios que se querían y la modificación constante debido a los distintos errores que aparecían en el proceso. Aunque se mencionó el mensaje de error anterior, también los hubo muchos más pero de estos no vale la pena discutir pues fueron resueltos con facilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPTURA DE DATOS DE GOOGLE MAPS USANDO HERRAMIENTA CHROMEDRIVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una de las actividades esenciales para continuar con el proyecto. Se utilizará la herramienta Chrome Driver. Esta herramienta se utiliza normalmente para la automatización de despliegue de pruebas para sitios web y aplicaciones. En este caso en específico lo que se realizó fue automatizar una serie de pasos de un proceso que consistía en:\n",
    "1. Utilizar el buscador de Google maps para consultar cierta cadena de caracteres.\n",
    "2. Capturar ciertos parámetros del fichero HTML que se despliega al momento de encontrar el sitio indicado.\n",
    "3. Guardar esta información en un fichero CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el primer paso, utilizado el fichero de registros que tenia Eixos, se construye un parametro que se buscará en el navegador cumpliendo ciertos condiciones. A continuacion se muestra como se realizo este paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../df_sup.csv', usecols=['title','street','number']).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['title'] == 'Anton Solé', 'title'] = 'Taller Anton Solé'\n",
    "df['title'] = df['title'].str.replace('F.Espunes','Talleres Espuña')\n",
    "df.loc[df['title'] == 'Herpa', 'title'] = 'Erpa'\n",
    "df.loc[df['title'] == 'Emauto S.C', 'number'] = '40'\n",
    "df.loc[df['title'] == 'Emauto S.C', 'title'] = 'Em Auto S.C.'\n",
    "df.loc[df['title'] == 'Findal', 'number'] = '128' \n",
    "df.loc[df['title'] == 'Findal', 'street'] = 'CL PUIG CERDÁ'\n",
    "df.loc[df['title'] == 'Tallers Ulibarri', 'title'] = 'Talleres Chicote'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que cambiar ciertos caractéres a algo que el buscador pueda manipular, por eso se cambian ciertas reducciones a su version normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['street'] = df['street'].str.replace('CL','Carrer')\n",
    "df['street'] = df['street'].str.replace('PZ','Plaça')\n",
    "df['street'] = df['street'].str.replace('PS','Passeig')\n",
    "\n",
    "df['serch_o'] = df['title']+' '+df['street']+', '+df['number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos que nos importaría pasarle al buscador serán la construcción de: \n",
    "* El nombre del establecimiento **+** La direccion del establecimiento (Calle, avenida,placa... ) **+** El número.  \n",
    "De esta manera cuando se pase este dato uno a uno en la consulta en el buscador sera posible conseguir la información pues esto es mas parecido a como un ser humano realizaría una busqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>number</th>\n",
       "      <th>street</th>\n",
       "      <th>serch_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Garces Taller</td>\n",
       "      <td>78</td>\n",
       "      <td>Carrer ROCAFORT</td>\n",
       "      <td>Garces Taller Carrer ROCAFORT, 78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Taller Anton Solé</td>\n",
       "      <td>10</td>\n",
       "      <td>Plaça NAVAS</td>\n",
       "      <td>Taller Anton Solé Plaça NAVAS, 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Auto.Carburación</td>\n",
       "      <td>1</td>\n",
       "      <td>Carrer TEODOR BONAPLATA</td>\n",
       "      <td>Auto.Carburación Carrer TEODOR BONAPLATA, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M.F, Flomart</td>\n",
       "      <td>30</td>\n",
       "      <td>Passeig MONTJUIC</td>\n",
       "      <td>M.F, Flomart Passeig MONTJUIC, 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Talleres Espuña</td>\n",
       "      <td>68</td>\n",
       "      <td>Passeig MONTJUIC</td>\n",
       "      <td>Talleres Espuña Passeig MONTJUIC, 68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title number                   street  \\\n",
       "0      Garces Taller     78          Carrer ROCAFORT   \n",
       "1  Taller Anton Solé     10              Plaça NAVAS   \n",
       "2   Auto.Carburación      1  Carrer TEODOR BONAPLATA   \n",
       "3       M.F, Flomart     30         Passeig MONTJUIC   \n",
       "4    Talleres Espuña     68         Passeig MONTJUIC   \n",
       "\n",
       "                                       serch_o  \n",
       "0            Garces Taller Carrer ROCAFORT, 78  \n",
       "1            Taller Anton Solé Plaça NAVAS, 10  \n",
       "2  Auto.Carburación Carrer TEODOR BONAPLATA, 1  \n",
       "3            M.F, Flomart Passeig MONTJUIC, 30  \n",
       "4         Talleres Espuña Passeig MONTJUIC, 68  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ya se tiene construido nuestro elemento, lo siguiente será ir a buscar dicho elemento que se pasa por la herramienta de automatización ChromeDrive.\n",
    "Los parámetros que nos interesaran son:\n",
    "* full_name: El nombre completo del establecimiento, COMO SE ENCUENTRA EN EL SITIO DE GOOGLE MAPS.\n",
    "* rating: El rating de valoraciones (5-0).\n",
    "* total_ratings: El número de personas que han realizado una reseña\n",
    "* landmark_cat: La categoría del establecimiento, SEGÚN LO CLASIFICA GOOGLE MAPS.\n",
    "* description: Descripción del establecimiento si la hay (normalmente no hay descripción).\n",
    "* address: La dirección del establecimiento, en la forma calle, avenida, plaza, pasaje... + número + código postal + ciudad\n",
    "* hours: Cuando está disponible, se captura el horario de atención y su nivel de concurrencia. (puede variar en horario diario(04 h-21 h,05 h-22 h,06 h-23 h)) y por días abiertos, como por ejemplo abierto todos los días, cerrando los sábados y domingos o solo los domingos.\n",
    "* lat: SEGÚN GOOGLE latitud del establecimiento.\n",
    "* long: SEGÚN GOOGLE longitud del establecimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74dfe179b474bd4adfa1f19c1d64e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2. Extracting the data', max=30, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument('headless')\n",
    "\n",
    "browser = webdriver.Chrome(options=options)\n",
    "\n",
    "landmarks = df['serch_o']# PS.full_name+' '+PS.address\n",
    "\n",
    "\n",
    "# We want to remove any '/' character in the names and addresses in the landmarks list (because they'll break URLs) :\n",
    "landmarks = [i.replace('/', ' ') for i in landmarks]\n",
    "\n",
    "# These are the empty lists we will populate with the extracted data :\n",
    "full_name = []\n",
    "rating = []\n",
    "total_ratings = []\n",
    "landmark_cat = []\n",
    "description = []\n",
    "address = []\n",
    "hours = []\n",
    "lat = []\n",
    "long = []\n",
    "    \n",
    "# Here's the big loop iterating over the landmarks list :\n",
    "for landmark in tqdmn(landmarks, leave=False, desc='2. Extracting the data') :\n",
    "    \n",
    "    # URL making :\n",
    "    url = 'https://www.google.com/maps/search/' + landmark\n",
    "    browser.get(url)\n",
    "\n",
    "    # Waiting for the name of the landmark to load and be visible. If it fails, skip to next one :\n",
    "    try :\n",
    "        WebDriverWait(browser,30).until(EC.visibility_of_element_located((By.CLASS_NAME, \"section-hero-header-title-title\")))\n",
    "    except (NoSuchElementException, TimeoutException) as e :\n",
    "        continue\n",
    "        \n",
    "    # Extracting the data and putting it into the empty lists we defined earlier :\n",
    "    try:\n",
    "        full_name.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]').text)\n",
    "    except NoSuchElementException :\n",
    "        full_name.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        rating.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[2]/div/div[1]/span[1]/span/span').text)\n",
    "    except NoSuchElementException :\n",
    "        rating.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        total_ratings.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[2]/div/div[1]/span[2]/span/span[1]/span[2]/span[1]/button').text)\n",
    "    except NoSuchElementException:\n",
    "        total_ratings.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        landmark_cat.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[2]/div/div[2]/span[1]/span[1]/button').text)\n",
    "    except NoSuchElementException:\n",
    "        landmark_cat.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        description.append(browser.find_element_by_css_selector('div[class=section-editorial-quote]').text)\n",
    "    except NoSuchElementException:\n",
    "        description.append(np.nan\n",
    "                          )\n",
    "    try:\n",
    "        address.append(browser.find_element_by_css_selector('div[data-tooltip=\"Copiar la dirección\"]').text)\n",
    "    except NoSuchElementException :\n",
    "        address.append(np.nan)\n",
    "\n",
    "    # Here we capture the popular hours for all 7 days starting with Sunday :\n",
    "    try:\n",
    "        hours.append([i.get_attribute('aria-label') for i in browser.find_elements_by_xpath(\"//*[contains(@aria-label, 'hora:')]\")])\n",
    "    except NoSuchElementException:\n",
    "        hours.append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        coordinates = browser.find_element_by_css_selector('meta[itemprop=image]').get_attribute('content')\n",
    "        coordinates = coordinates.split('?center=')[1].split('&zoom=')[0].split('%2C')\n",
    "        lat.append(coordinates[0])\n",
    "        long.append(coordinates[1])\n",
    "    except NoSuchElementException:\n",
    "        lat.append(np.nan)\n",
    "        long.append(np.nan)\n",
    "\n",
    "# Closing the Chrome window\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas maneras de buscar los datos que interesan usando esta herramienta, se debe usar el fichero HTML para ir buscando contenedores u objetos. Es importante tener un conocimiento mínimo de HTML para realizar esta etapa. Sobre todo es para poder encontrar de manera específica los parámetros que nos interesan.  \n",
    "Además es de reconocer la potencia de esta herramienta pues se pueden definir diversos pasos para que automáticamente dadas algunas condiciones pueda capturar más información navegando o escogiendo entre una lista de elementos al momento de realizar una búsqueda.  \n",
    "Una perspectiva interesante para este proyecto seria guardar las reseñas que los usuarios ha dejado en cada comercio y realizar un análisis de NLP, solo por mencionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "HL = pd.DataFrame(data={'full_name':full_name, 'rating':rating, 'total_ratings':total_ratings, 'landmark_category':landmark_cat, 'description':description, 'address':address, 'hours':hours})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"t_dataRaw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se ordena como un DataFrame de Pandas, aunque lo que se vea de los primeros registros parezca poca información en realidad en cada registro de la columna hours lo que se podría encontrar es algo como lo que se observa en imagen siguiente. Sin embargo toda esta información como se visualizará a continuación es información de la actividad del establecimiento a cada hora durante cada día de actividad. Esto quiere decir que si se tiene información de un establecimiento que está abierto seis días a la semana con un horario de 6 de la mañana a 23 horas toda esta información no representa, en el sentido practico, un dato que aporte al análisis. Por lo tanto desde la perspectiva del analista fue conveniente proponer que esta información se comprimiera de alguna manera haciendo la media de la actividad en el establecimiento. Lo anterior se podrá observar con el transcurso de este Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"t_colHour_dataRaw.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(list(HL[HL.full_name == 'MF Flomart'].hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_planner(place_name) :\n",
    "\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :'Sunday', \n",
    "    place_name = pd.DataFrame(index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "    #place_name = pd.DataFrame(index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],  \\\n",
    "                              columns=['06','07','08','09','10','11','12','13','14','15','16','17','18','19','20',\n",
    "                                       '21','22','23'])    \n",
    "    \n",
    "    # and then we return that dataframe\n",
    "    return place_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"empty_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada establecimiento se tendrá que crear una tabla vacía con los días de actividad y las horas activas. Lo anterior podrían ser de cinco a siete días y siempre serán diez y ocho horas de actividad, lo que variaría en este caso serian los rangos de las horas de actividad pudiendo comenzar más temprano en algunos casos o más tarde en otros. Por lo tanto aquí es donde reside la dificultad de este proceso, pues según para cada caso que lo requiera el horario y los días de atención de cada establecimiento se debería crear la tabla adecuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = visit_planner(\"t_table\")\n",
    "\n",
    "# we need to remove the row for Sunday before proceeding\n",
    "table.drop('Saturday', axis=0, inplace=True)\n",
    "\n",
    "for hour in list(table):\n",
    "    table[hour] = re.findall('.{0,29}hora: '+str(hour)+'..', str(list(HL[HL.full_name=='MF Flomart'].hours)))\n",
    "    table[hour] = [ re.findall('\\d+', str(i))[0] for i in tall2[hour] ]\n",
    "    table[hour] = table[hour].astype(int)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(table, cmap='PuBu', linewidths=0.8, annot=True, annot_kws={'fontsize':8, 'alpha':0.8}, fmt='d', square=True,\n",
    "           cbar=False)\n",
    "\n",
    "plt.xticks(np.arange(18), list(tall2))\n",
    "plt.title(\"Popular times visiting MF Flomart\\n\", weight='semibold')\n",
    "\n",
    "# this bit of code ensures the heatmap will not show up truncated with some versions of matplotlib\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"filled_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo es correcto, uno podría encontrar una tabla rellenada como la se observa en la parte superior, y de manera gráfica como se observa en la figura siguiente (la tabla gráfica solo es útil para darse una idea de la distribución a lo largo de una semana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"show_ftable.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de esto es conseguir de la tabla anterior, lo que era la tabla rellenada con los valores a cada hora, una tabla **.describe()**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"describe_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y aún cuando ya se tuviera lo anterior, la idea final es comprimir esta información haciendo la media de la anterior tabla:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"reduced_described_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí se ha explicado como se obtuvieron los datos de cada consulta que se fueron realizando en google Maps de cada registro en los datos que tenía Eixos. Además se ha explicado un poco de la idea que se tiene para enriquecer más cada registro de este data set que se obtuvo de Google haciendo uso de la columna hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAR MAS INFORMACIÓN A PARTIR DE LA COLUMNA HOURS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta esta parte del proceso se asume que ya se tiene toda la información que se pudo obtener de las consultas realizadas a Google maps. Se puede utilizar un parámetro, ```glob``` para obtener una lista con los ficheros ```csv``` que están disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hfull_stcl_ldmks_attem19798_succ6095.csv', 'hfull_stcl_ldmks_attem33872_succ10300.csv', 'hfull_stcl_ldmks_attem35886_succ1033.csv', 'hfull_stcl_ldmks_attem36514_succ424.csv', 'hfull_stcl_ldmks_attem38201_succ559.csv', 'hfull_stcl_ldmks_attem38849_succ287.csv', 'hfull_stcl_ldmks_attem39701_succ256.csv', 'hfull_stcl_ldmks_attem41723_succ662.csv', 'hfull_stcl_ldmks_attem45541_succ917.csv', 'hfull_stcl_ldmks_attem47051_succ623.csv', 'hfull_stcl_ldmks_attem50323_succ1553.csv', 'hfull_stcl_ldmks_attem50969_succ240.csv', 'hfull_stcl_ldmks_attem51465_succ151.csv', 'hfull_stcl_ldmks_attem53551_succ706.csv', 'hfull_stcl_ldmks_attem59786_succ1368.csv', 'hfull_stcl_ldmks_attem63950_succ1057.csv', 'hfull_stcl_ldmks_attem65546_succ463.csv', 'hfull_stcl_ldmks_attem69434_succ503.csv', 'hfull_stcl_ldmks_attem69894_succ176.csv', 'table_of_MEANS_googleData.csv']\n"
     ]
    }
   ],
   "source": [
    "# Primero especificamos un patrón del archivo y lo pasamos como parámetro en la función glob\n",
    "csv_files = glob.glob('*.csv')\n",
    "# Mostrar el archivo csv_files, el cual es una lista de nombres\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['hfull_stcl_ldmks_attem19798_succ6095.csv',\n",
    "             'hfull_stcl_ldmks_attem33872_succ10300.csv',\n",
    "             'hfull_stcl_ldmks_attem35886_succ1033.csv',\n",
    "             'hfull_stcl_ldmks_attem36514_succ424.csv',\n",
    "             'hfull_stcl_ldmks_attem38201_succ559.csv',\n",
    "             'hfull_stcl_ldmks_attem38849_succ287.csv',\n",
    "             'hfull_stcl_ldmks_attem39701_succ256.csv',\n",
    "             'hfull_stcl_ldmks_attem41723_succ662.csv',\n",
    "             'hfull_stcl_ldmks_attem45541_succ917.csv',\n",
    "             'hfull_stcl_ldmks_attem47051_succ623.csv',\n",
    "             'hfull_stcl_ldmks_attem50323_succ1553.csv',\n",
    "             'hfull_stcl_ldmks_attem50969_succ240.csv',\n",
    "             'hfull_stcl_ldmks_attem51465_succ151.csv',\n",
    "             'hfull_stcl_ldmks_attem53551_succ706.csv',\n",
    "             'hfull_stcl_ldmks_attem59786_succ1368.csv',\n",
    "             'hfull_stcl_ldmks_attem63950_succ1057.csv',\n",
    "             'hfull_stcl_ldmks_attem65546_succ463.csv',\n",
    "             'hfull_stcl_ldmks_attem69434_succ503.csv',\n",
    "             'hfull_stcl_ldmks_attem69894_succ176.csv']\n",
    "list_data = []\n",
    "  \n",
    "# Escribimos un loop que irá a través de cada uno de los nombres de archivo a través de globbing y el resultado final será la lista dataframes\n",
    "\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "\n",
    "df_concat = pd.concat(list_data,ignore_index=True)\n",
    "df_concat = df_concat.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues con un ciclo se puede ir formado una lista con los elementos de la lista para que de último se pueda concatenar toda la lista. Como ultimo paso es importante retirar los duplicados. Así es como se obtiene el dataset definitivo de todas las consultas realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21526, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ve anteriormente los registros únicos son 21526, aunque los que se obtuvieron fueron aproximadamente 22mil y un poco más.  \n",
    "Luego al tener listo en un solo DataFrame todos los registros se crea una nueva tabla vacía donde se guardará la información que se generará por cada registro que cumpla con las condiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = pd.DataFrame(index = df_concat.index.values, \\\n",
    "                       columns=('count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente función lo que se hace es declarar tablas para los cuatro casos de horarios que se considerarán:\n",
    "* de 24h a 17h\n",
    "* de 04h a 21h\n",
    "* de 05h a 22h\n",
    "* de 06h a 23h  \n",
    "\n",
    "Todas la tablas asumen al inicio que si se invocan se crearán con los siete dias y si se tiene que eliminar un día, pues así sera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_planner0_17(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['24','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17'])    \n",
    "    return place_name\n",
    "\n",
    "def visit_planner4_21(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21'])    \n",
    "    return place_name\n",
    "\n",
    "def visit_planner5_22(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22'])    \n",
    "    return place_name\n",
    "\n",
    "\n",
    "def visit_planner6_23(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23'])    \n",
    "    return place_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para eliminar formato:  \n",
    "    ```'Nivel de ocupación: 17\\\\\\\\\\\\\\\\xa0% (hora: 18:00)``` -> X  \n",
    "    ```'Nivel de ocupación: 17\\\\\\\\\\\\\\\\xa0% (hora: 18)``` -> OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supZeros(chnk):\n",
    "    line = str(list(df_concat[df_concat.index == chnk].hours))\n",
    "    df_concat['hours'][chnk] = re.sub('\\:00\\)', ')', line)[2:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para cambiar ciertos registros donde los siete dias de la semana pero seis dias a las 05 h hasta las 22 h y un dia a las 06 h hasta las 23h.  \n",
    "Lo que se hacia aqui era cambiar el registro con la hora 23 por el registro de la hora 05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chgTtbyFi(chnk):\n",
    "    lsd = []\n",
    "    sd = str(df_concat['hours'][chnk]).split(',')\n",
    "    for i in sd:\n",
    "            if bool(re.findall('\\: 23\\)', i)) == True:\n",
    "                sd[sd.index(i)] = ' Nivel de ocupación:  0\\\\xa0% (hora: 05).' \n",
    "                print(i, chnk)\n",
    "    df_concat['hours'][chnk] = sd[2:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para solucionar registros de establecimeintos que se capturaban justo cuando estos estaban abiertos y se mostraba en tiempo real la afluencia de personas y por otro lado se tenía la afluencia habitual de los establecimientos. Este fue un serio problema pues si no se solucionaba se perdía esta información, información que si estaba pero no en le formato que se esperaba.  \n",
    "  \n",
    "La situación era este tipo de formato:  \n",
    "`...`  \n",
    "`\" 'Nivel de ocupación: 54\\\\\\\\xa0% (hora: 24).'\",`  \n",
    "`\" 'Nivel de ocupación: 39\\\\\\\\xa0% (hora: 01).'\",`  \n",
    "`\" 'Nivel de ocupación actual: 0\\\\\\\\xa0%. Nivel de ocupación habitual: 27\\\\\\\\xa0%.'\",`   \n",
    "`\" '0%'\",`  \n",
    "`' \\'Nivel de ocupación: 17\\\\\\\\xa0% (hora: 03)`  \n",
    "`...`  \n",
    "Lo que se desea es algo como esto:  \n",
    "`...`  \n",
    "`\" 'Nivel de ocupación: 54\\\\\\\\xa0% (hora: 24).'\",`  \n",
    "`\" 'Nivel de ocupación: 39\\\\\\\\xa0% (hora: 01).'\",`  \n",
    "`\" 'Nivel de ocupación: 27\\\\\\\\xa0% (hora: 02).'\",`   \n",
    "`' \\'Nivel de ocupación: 17\\\\\\\\xa0% (hora: 03)`  \n",
    "`...`  \n",
    "  \n",
    "Esto es lo que se encarga de hacer esta función, corregir este formato y eliminar ese elemento que esta de sobra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambioValSpl(chnk):\n",
    "        sd = str(df_concat['hours'][chnk]).split(',')\n",
    "        lst = []\n",
    "        lsd = []\n",
    "        for i in sd:\n",
    "            lst.append(len(i))\n",
    "            if len(i) < 40:\n",
    "                lsd.append(sd.index(i))\n",
    "        posMax = lst.index(max(lst))\n",
    "        sd = str(df_concat['hours'][chnk]).split(',')\n",
    "        lst=[]\n",
    "        i = str(re.findall('.{0,10}habitual.{0,11}', str(list(df_concat[df_concat.index==chnk].hours))))[2:-2]\n",
    "        ii = int(re.findall('\\d+',i)[0])\n",
    "        isw = int(re.findall('\\d+',sd[posMax-1])[2])+1\n",
    "        #'Nivel de ocupación: 29\\\\xa0% (hora: 16).'\n",
    "        if isw < 10:\n",
    "            sd[posMax] = ' \\'Nivel de ocupación: '+str(ii)+'\\\\xa0% (hora: 0'+ str(isw) +').'\n",
    "        else: \n",
    "            sd[posMax] = ' \\'Nivel de ocupación: '+str(ii)+'\\\\xa0% (hora: '+ str(isw) +').'\n",
    "        sd = np.delete(sd,lsd)\n",
    "        df_concat['hours'][chnk] = sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui es donde se ejecuta la funcio del cambio de formato, pero solo para los que tengan la palabra clave **habitual**, lo que hace es enviar el valor del indice de este registro y a partir de alli hace todo el proceso necesario para cambiar el formato de ese registro, manipulando solamente aquello que esta mal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alter\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dfConcat_inx = df_concat.index.values\n",
    "for i in dfConcat_inx:\n",
    "    if bool(re.search(\"habitual.\",str(list(df_concat[df_concat.index == i].hours)))) == True:\n",
    "        cambioValSpl(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se eliminan los:   \n",
    "```['30% concurrido a la(s) 09:00',\n",
    " '26% concurrido a la(s) 09:00',\n",
    " '26% concurrido a la(s) 09:00',\n",
    " '43% concurrido a la(s) 09:00',\n",
    " '52% concurrido a la(s) 09:00',\n",
    " '39% concurrido a la(s) 09:00']```  \n",
    "\n",
    "Por un formato asi:  \n",
    "```['30% concurrido a la(s) 09',\n",
    " '26% concurrido a la(s) 09',\n",
    " '26% concurrido a la(s) 09',\n",
    " '43% concurrido a la(s) 09',\n",
    " '52% concurrido a la(s) 09',\n",
    " '39% concurrido a la(s) 09']```  \n",
    "   \n",
    "Esto es porque asi se decicio por convención en este análisis, además la mayoria de los registros tenían el formato sin los *:00*, entoces se opto por dejarlo asi. Por ultimo como razon principal fue porque es mas facil manejar este tipo de formato al momento de rellenar la tabla con los valores de afluencia por dia/hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alter\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dfConcat_inx = df_concat.index.values\n",
    "for i in dfConcat_inx:\n",
    "    \n",
    "    if bool(re.search(\"\\:00\",str(list(df_concat[df_concat.index == i].hours)))) == True:\n",
    "        supZeros(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de limpiar y tratar que los datos fueran lo más homogéneos posibles, aquí se presenta la parte más importante del código, pues aquí se decidirá a que tabla se llamará, no obstante esto dependerá de una verificación de lo que se halla en el registro. Como se mencionó al inicio hubieron ciertas condiciones que se tomaron en cuenta. Como primer paso lo que se realiza es crear dos listas en un array numpy, por un lado los indices de cada uno de los registros en el data set y por otro lado la longitud de los elementos que estan almacenados en esos registros, con esto podremos darnos una idea de que es lo que tenemos guardado. Algunas pautas esenciales fueron:  \n",
    "\n",
    "Condiciones esenciales:  \n",
    "* Se asume que un día de trabajo tendra al menos 18 horas de actividad\n",
    "* se asume que para el analisis solmamente se utilizará la información de lo establecimientos que esten abiertos cinco dias o mas.\n",
    "* Teniendo en cuenta lo anterior, logicamente el valor mínimo de a longitud de los registros que se analizaran seran los que sean igual o más a 90 elementos. Porque 5\\*18=90  \n",
    "\n",
    "Valores mínimos:  \n",
    "* SIETE DIA -> 7\\*18 = 126  \n",
    "* SEIS DIAS -> 6\\*18 = 108  \n",
    "* CINCO DIAS -> 5\\*18 = 90  \n",
    "\n",
    "Los valores anteriores por dia representan los valores minimos en cada caso, pues en algunos registros se tiene actividad muchas mas horas pero para este analisis solo seran utiles 18h por dia, por lo tanto aqui es donde entra nuestro proceso de verificación.\n",
    "Antes de crear esa tabla vacia que nos sera útil, se debe verificar, para esto se contará de forma estrategia el numero de ocurrencias de ciertas horas que se observaron que eran las mas determinantes . Definir estas horas estrategicas se logró despues de analizar mucho tiempo la naturaleza de la información que se encontraba en los  registros de la columna hours. En teoría, se tendría que verificar que para cada caso existan los mismos numeros de ocurrencias de las horas, es decir que de un establecimiento que abre los siete dias de la semana con un intérvalo de 18 h que va de 05 h a 22 h, se deben encontrar siete registros de la hora 05, siete registros de la hora 06, siete registros de la hora 07... asi sucesivamente hasta por ultimo verificar la hora 22. Lo anterior aunque sea lo mas correcto no es lo mas eficiente, por lo tanto se buscaron ciertas horas especificas para dar con la tabla correcta que fuera necesaria para cada caso.  \n",
    "Cuando ya se haya verificado que tipo de informacion es la que existe dentro del registro entonces se llama a la funcion que crea la tabla mas adecuada. Luego a menos que sea un estableciemiento que este abierto los siete dias de la semana se crea la tabla y listo, de lo contrario se tendra que que eliminar los dias que sean necesarios, siendo posibles los casos de eliminar el domingo o el sabado y el domingo.\n",
    "Ahora si, cuando ya se tiene la tabla correcta, creada y vacia es cuando se rellena. En el paso de verificacion se habían utilizado algunas funciones regex, sobre todo para encontrar patrones detro de estos bloques de información. Sin embargo, en este caso si que se se utilizan de manera que se vayan guardando y asigano a cada espacio que le corresponde detro de la tabla.  \n",
    "Luego que ya se tiene esa tabla con los valores, creamos un Dataframe vacio al que se le asigará la tabla *describe* de la anterior tabla pero transpuesta y cuando ya esta lista es a esta tabla a la que se le aplica la función *mean()* y en este punto es donde tenemos la informacion comprimida del registro. Lo que queda es guaradar estas nuevas columnas con un registro de la tabla comp_df () fue la tabla vacia que declaramos en pasos anteriores con los indices de la tabla df_concant. De ese registro en específico se guaradará la media de la información las siguientes columnas:  \n",
    "\n",
    "   * count \t\n",
    "   * mean  \n",
    "   * std \t\n",
    "   * min \t\n",
    "   * 25% \t\n",
    "   * 50% \t\n",
    "   * 75% \t\n",
    "   * max  \n",
    "\n",
    "Es asi como se comprime toda la información y como al final toda esta tabla con informacion de establecimeintos que estan abiertos 5, 6 o 7 dias con un itnervalo de 18 h se pueden guardar a la par de la tabal df_concat, la tabla donde encontramos informacion de los registros como el nombre, su direcion, las reseñas y valoraciones entro otras cosas. Es asi como finalmente se ha enriquecido este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5470"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HL_inx = df_concat.index.values\n",
    "cntPer= df_concat.hours.apply(lambda x: len(str(x).split(',')))\n",
    "#cntPer = df_concat.hours.apply(lambda x: len(x.split(',')))\n",
    "arrInf = np.column_stack((HL_inx,cntPer))\n",
    "vac = []\n",
    "iver = []\n",
    "#sev = False\n",
    "\n",
    "# visit_plannerD visit_plannerC visit_plannerS\n",
    "\n",
    "\n",
    "for (i, j) in arrInf:\n",
    "    if j >= 90:\n",
    "        \n",
    "        sev = False\n",
    "        six = False\n",
    "        fiv = False\n",
    "        \n",
    "        #SIETE DIAS\n",
    "        if (len(re.findall('.{0,36}04'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}21'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 ):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner4_21(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1] \n",
    "            sev = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and sev == False):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner5_22(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1] \n",
    "            sev = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}23'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and sev == False):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner6_23(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]   \n",
    "            sev = True\n",
    "                    \n",
    "        if (len(re.findall('.{0,36}24'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}03'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}17'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and sev == False):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner0_17(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]           \n",
    "            sev = True\n",
    "            \n",
    "        #SEIS DIAS            \n",
    "        if (len(re.findall('.{0,36}04'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}21'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False ):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner4_21(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "\n",
    "        if (len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False and six == False ):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            \n",
    "            t_table = visit_planner5_22(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}23'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False and six == False ):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            \n",
    "            t_table = visit_planner6_23(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}24'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}03'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}17'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False and six == False ):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner0_17(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "            \n",
    "        #CINCO DIAS\n",
    "        if (len(re.findall('.{0,36}04'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}21'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner4_21(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            fiv = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False and fiv == False):\n",
    "            #print(i, j,'tabla de cinco dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner5_22(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            fiv = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}23'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False and fiv == False):\n",
    "            #print(i, j,'tabla de cinco dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner6_23(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            fiv = True\n",
    "        if (len(re.findall('.{0,36}24'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}03'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}17'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False and fiv == False):\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner0_17(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "        if(fiv == True or six == True or sev == True):\n",
    "            iver.append(i)\n",
    "len(vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>18.9444</td>\n",
       "      <td>8.10061</td>\n",
       "      <td>10.5556</td>\n",
       "      <td>14.1667</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21.9444</td>\n",
       "      <td>30.5556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21526 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     mean      std      min      25%   50%      75%      max\n",
       "0       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "1       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "2       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "3         5  18.9444  8.10061  10.5556  14.1667  17.5  21.9444  30.5556\n",
       "4       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "...     ...      ...      ...      ...      ...   ...      ...      ...\n",
       "21521   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21522   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21523   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21524   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21525   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "\n",
       "[21526 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente aqui se une la información original de Google Maps de los registros y la información que surge de la columna hours. Es importante mencionar que aqui solo se contemplo los valores de la media de la tabla describe() de cada registro, pero podrian obtenerse otros valores que podrian resultar interesantes como la sumatoria de los porcentajes de afluencia o solamente tener en cuenta ciertos dias de la semana o que la tabla describre() no fuera sobre las horas sino sobre los dias, etc. En realidad se podrian obtener mas datos estadisticos de los registros de la columna **hour**, pero eso queda como un comentario, pues en este proyecto no se abordarán más de esas combinaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_ratings</th>\n",
       "      <th>landmark_category</th>\n",
       "      <th>description</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>hours</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Tallers Garcés</td>\n",
       "      <td>4,1</td>\n",
       "      <td>(10)</td>\n",
       "      <td>Taller de automóviles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Rocafort, 78, 08015 Barcelona</td>\n",
       "      <td>934 23 10 93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.379371</td>\n",
       "      <td>2.153754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Taller Antón Solé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plaça de las Navas, 10, 08004 Barcelona</td>\n",
       "      <td>934 23 45 63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.374035</td>\n",
       "      <td>2.158775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Auto Carburacion e Inyeccion</td>\n",
       "      <td>5,0</td>\n",
       "      <td>(2)</td>\n",
       "      <td>Taller de reparación de vehículos todoterreno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C/ d'Entença, 20, 08015 Barcelona</td>\n",
       "      <td>933 25 46 94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.376014</td>\n",
       "      <td>2.155615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MF Flomart</td>\n",
       "      <td>4,9</td>\n",
       "      <td>(35)</td>\n",
       "      <td>Tienda de repuestos para automóviles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passeig de Montjuïc, 30, 08004 Barcelona</td>\n",
       "      <td>934 41 13 48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Nivel de ocupación: \\xa0% (hora: ).', 'Nivel...</td>\n",
       "      <td>41.372421</td>\n",
       "      <td>2.171510</td>\n",
       "      <td>5</td>\n",
       "      <td>18.9444</td>\n",
       "      <td>8.10061</td>\n",
       "      <td>10.5556</td>\n",
       "      <td>14.1667</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21.9444</td>\n",
       "      <td>30.5556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Talleres Espuña</td>\n",
       "      <td>4,6</td>\n",
       "      <td>(10)</td>\n",
       "      <td>Taller de reparación de automóviles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passeig de Montjuïc, 68, 08004 Barcelona</td>\n",
       "      <td>934 41 48 10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.371756</td>\n",
       "      <td>2.167712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21521</td>\n",
       "      <td>De Pata Negra</td>\n",
       "      <td>3,7</td>\n",
       "      <td>(264)</td>\n",
       "      <td>Bar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plaça de las Navas, 7, 08004 Barcelona, España</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.facebook.com</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.373856</td>\n",
       "      <td>2.159229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21522</td>\n",
       "      <td>Malabida</td>\n",
       "      <td>4,5</td>\n",
       "      <td>(171)</td>\n",
       "      <td>Bar restaurante</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Blai, 63, 08004 Barcelona, España</td>\n",
       "      <td>+34 931 75 81 79</td>\n",
       "      <td>malabida.business.site</td>\n",
       "      <td>['Nivel de ocupación: 0\\\\xa0% (hora: 04).', 'N...</td>\n",
       "      <td>41.374590</td>\n",
       "      <td>2.161894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21523</td>\n",
       "      <td>Bodega 1900</td>\n",
       "      <td>4,4</td>\n",
       "      <td>(990)</td>\n",
       "      <td>Bar de tapas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Tamarit, 91, 08015 Barcelona, España</td>\n",
       "      <td>+34 933 25 26 59</td>\n",
       "      <td>elbarri.com</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.375552</td>\n",
       "      <td>2.156562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21524</td>\n",
       "      <td>Vinoteca San Antoni By Wine Palace</td>\n",
       "      <td>4,5</td>\n",
       "      <td>(68)</td>\n",
       "      <td>Bodega</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer del Comte Borrell, 30, 08015 Barcelona,...</td>\n",
       "      <td>+34 935 39 40 02</td>\n",
       "      <td>winepalace.es</td>\n",
       "      <td>['Nivel de ocupación: \\\\xa0% (hora: ).', 'Nive...</td>\n",
       "      <td>41.376737</td>\n",
       "      <td>2.163638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21525</td>\n",
       "      <td>Bodega Xavier Can Anxoves</td>\n",
       "      <td>5,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Vallhonrat, 18, 08004 Barcelona, España</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.374166</td>\n",
       "      <td>2.156982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21526 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                full_name rating total_ratings  \\\n",
       "0                          Tallers Garcés    4,1          (10)   \n",
       "1                       Taller Antón Solé    NaN           NaN   \n",
       "2            Auto Carburacion e Inyeccion    5,0           (2)   \n",
       "3                              MF Flomart    4,9          (35)   \n",
       "4                         Talleres Espuña    4,6          (10)   \n",
       "...                                   ...    ...           ...   \n",
       "21521                       De Pata Negra    3,7         (264)   \n",
       "21522                            Malabida    4,5         (171)   \n",
       "21523                         Bodega 1900    4,4         (990)   \n",
       "21524  Vinoteca San Antoni By Wine Palace    4,5          (68)   \n",
       "21525           Bodega Xavier Can Anxoves    5,0           NaN   \n",
       "\n",
       "                                   landmark_category description  \\\n",
       "0                              Taller de automóviles         NaN   \n",
       "1                                                NaN         NaN   \n",
       "2      Taller de reparación de vehículos todoterreno         NaN   \n",
       "3               Tienda de repuestos para automóviles         NaN   \n",
       "4                Taller de reparación de automóviles         NaN   \n",
       "...                                              ...         ...   \n",
       "21521                                            Bar         NaN   \n",
       "21522                                Bar restaurante         NaN   \n",
       "21523                                   Bar de tapas         NaN   \n",
       "21524                                         Bodega         NaN   \n",
       "21525                                            NaN         NaN   \n",
       "\n",
       "                                                 address             phone  \\\n",
       "0                Carrer de Rocafort, 78, 08015 Barcelona      934 23 10 93   \n",
       "1                Plaça de las Navas, 10, 08004 Barcelona      934 23 45 63   \n",
       "2                      C/ d'Entença, 20, 08015 Barcelona      933 25 46 94   \n",
       "3               Passeig de Montjuïc, 30, 08004 Barcelona      934 41 13 48   \n",
       "4               Passeig de Montjuïc, 68, 08004 Barcelona      934 41 48 10   \n",
       "...                                                  ...               ...   \n",
       "21521     Plaça de las Navas, 7, 08004 Barcelona, España               NaN   \n",
       "21522        Carrer de Blai, 63, 08004 Barcelona, España  +34 931 75 81 79   \n",
       "21523     Carrer de Tamarit, 91, 08015 Barcelona, España  +34 933 25 26 59   \n",
       "21524  Carrer del Comte Borrell, 30, 08015 Barcelona,...  +34 935 39 40 02   \n",
       "21525  Carrer de Vallhonrat, 18, 08004 Barcelona, España               NaN   \n",
       "\n",
       "                      website  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "...                       ...   \n",
       "21521          m.facebook.com   \n",
       "21522  malabida.business.site   \n",
       "21523             elbarri.com   \n",
       "21524           winepalace.es   \n",
       "21525                     NaN   \n",
       "\n",
       "                                                   hours   latitude  \\\n",
       "0                                                     []  41.379371   \n",
       "1                                                     []  41.374035   \n",
       "2                                                     []  41.376014   \n",
       "3      ['Nivel de ocupación: \\xa0% (hora: ).', 'Nivel...  41.372421   \n",
       "4                                                     []  41.371756   \n",
       "...                                                  ...        ...   \n",
       "21521                                                 []  41.373856   \n",
       "21522  ['Nivel de ocupación: 0\\\\xa0% (hora: 04).', 'N...  41.374590   \n",
       "21523                                                 []  41.375552   \n",
       "21524  ['Nivel de ocupación: \\\\xa0% (hora: ).', 'Nive...  41.376737   \n",
       "21525                                                 []  41.374166   \n",
       "\n",
       "       longitude count     mean      std      min      25%   50%      75%  \\\n",
       "0       2.153754   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "1       2.158775   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "2       2.155615   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "3       2.171510     5  18.9444  8.10061  10.5556  14.1667  17.5  21.9444   \n",
       "4       2.167712   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "...          ...   ...      ...      ...      ...      ...   ...      ...   \n",
       "21521   2.159229   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21522   2.161894   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21523   2.156562   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21524   2.163638   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21525   2.156982   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "\n",
       "           max  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3      30.5556  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "21521      NaN  \n",
       "21522      NaN  \n",
       "21523      NaN  \n",
       "21524      NaN  \n",
       "21525      NaN  \n",
       "\n",
       "[21526 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_GoogleMaps = pd.merge(df_concat, comp_df, left_index=True, right_index=True, how='outer')\n",
    "final_GoogleMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_GoogleMaps.to_csv('table_of_MEANS_googleData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_GoogleMaps = pd.read_csv('table_of_MEANS_googleData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_GoogleMaps['id'] = final_GoogleMaps.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_GoogleMaps.to_csv('table_of_MEANS_googleData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
