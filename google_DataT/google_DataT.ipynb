{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import time, re\n",
    "from tqdm import tqdm_notebook as tqdmn\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException, ElementClickInterceptedException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "# BREVE INFORMACIÓN IMPORTANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación de cuanto tiempo y como fue el proceso de scraping real  \n",
    "Esta parte del proceso ha tardado 4 dias aproximadamente en realizarse (se estima este intervalo de tiempo sin tener en cuenta el tiempo que se perdia cuando ocurrian las interrupciones abrutpas).\n",
    "Factor importante para continuar es que los registros que se consultaron fueron los aproximadamente ochenta mil registros que proporciono Eixos al inicio de este analisis.\n",
    "Teniendo en cuenta que serian ochenta mil consultas, el scraping al necesitar mucho tiempo de procesamiento y tambien de que el ordenor donde trabajaba no lo queria dejar de utilizar para que hiciera esta fase. Por lo tanto use un ordenador viejo que tenia guardado. A este ordenador le instale Ubuntu 18 y la distribución de Anaconda. La idea fue dedicar a que directamente este ordenador estuviera consultando este dataset.  \n",
    "Y asi fue, para esto tambien se tuvo que instalar el ChromeDriver para linux, la libreria Selenium y Folium. En cuanto a esto, se debe mencionar que toda la configuracion en linux se realizo por linea de comandos. Pero sin contratiempos, se fueron desarrollando bien las consultas.\n",
    "Esto hasta que despues de consultar 25mil registros un error no dejo seguir haciendo consultas. Este suceso se siguio repitiendo hasta el final de las consultas por lo que muchas veces las consultas fueron paradas abrutamente y por esta razon hay 19 datasets donde el primer numero en el nombre de cada fichero csv indica el registro hasta el que se consulto y el segundo numero indica cuantos registros se obtuvieron satisfactoriamente y quedaron guardados en dicho fichero.  \n",
    "El celebre error fue este: \n",
    "  \n",
    "***TimeoutException: Message: timeout: Timed out receiving message from renderer: 16,270(Session info: headless chrome=81.0.4044.122)***  \n",
    "  \n",
    "Este problema recurrente se consulto en foros como StackOverflow y si que aparecia y se aplicaron las medidas que se sugerian, y si que aliviaban las interrupciones del codigo de consulta pero al final siempre volvia a ocurrir. Una hipotesis es que este problema se debia a que al haber realizado muchas consultas desde mi ordenador de alguna manera mi ip fue baneada o puesta en una black list. Esta hipotesis tomaba fuerza pues al principio las consultas y los registros encontrados satisfactoriamente fueron en gran manera exitosos, pero despues se volvio lento y constantemente interrupido. Puede ser que esto se haya debido a que al principio no utlice ningun tipo de VPN. Luego si que se hizo el cambio y configurando en la terminal el servicicio HideMyVPN el proceso si que avanzo mejor.\n",
    "Finalmente este proceso tomo varios dias, aproximadamente dos semanas, entre las interrupciones, la consecucion del codigo definitivo que retornara los parametros necesrios que se querian y la modificacion constante debido a los distintos errores que aparecian en el proceso. Aunque se menciono el mensaje de error anterior, tambien los hubieron muchos mas pero de estos no vale la pena discutir pues fueron resultos con facilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPTURA DE DATOS DE GOOGLE MAPS USANDO HERRAMIENTA CHROMEDRIVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una de las actividades escenciales para continuar con el proyecto. Se utilizará la herramienta Chrome Driver. Esta herramienta se utliza normalmente para la automatización de despliegue de pruebas para sitios web y aplicaciones. En este caso en especifico lo que se realizo fue automatizar una serie de pasos de un proceso que consistia en:\n",
    "1. Utilizar el buscador en Google maps algunos de cierta cadena de caracteres.\n",
    "2. Capturar ciertos parametros de fichero xml que se despliega en al momento de econtrar el sitio indicado.\n",
    "3. Guardar esta informacion en un fichero csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el primer paso, utilizado el fichero de registros que tenia Eixos, se construye un parametro que se buscará en el navegador cumpliendo ciertos condiciones. A continuacion se muestra como se realizo este paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../df_sup.csv', usecols=['title','street','number']).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['title'] == 'Anton Solé', 'title'] = 'Taller Anton Solé'\n",
    "df['title'] = df['title'].str.replace('F.Espunes','Talleres Espuña')\n",
    "df.loc[df['title'] == 'Herpa', 'title'] = 'Erpa'\n",
    "df.loc[df['title'] == 'Emauto S.C', 'number'] = '40'\n",
    "df.loc[df['title'] == 'Emauto S.C', 'title'] = 'Em Auto S.C.'\n",
    "df.loc[df['title'] == 'Findal', 'number'] = '128' \n",
    "df.loc[df['title'] == 'Findal', 'street'] = 'CL PUIG CERDÁ'\n",
    "df.loc[df['title'] == 'Tallers Ulibarri', 'title'] = 'Talleres Chicote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['street'] = df['street'].str.replace('CL','Carrer')\n",
    "df['street'] = df['street'].str.replace('PZ','Plaça')\n",
    "df['street'] = df['street'].str.replace('PS','Passeig')\n",
    "\n",
    "df['serch_o'] = df['title']+' '+df['street']+', '+df['number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos que nos importara pasarle al buscador sera la construccion de: \n",
    "* El nombre del establecimiento + La direccion del establecimiento (Calle, avenida,placa... /numero)\n",
    "De esta manera cuando se pase este dato uno a uno en la consulta en el buscador sera posible conseguir la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>number</th>\n",
       "      <th>street</th>\n",
       "      <th>serch_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Garces Taller</td>\n",
       "      <td>78</td>\n",
       "      <td>Carrer ROCAFORT</td>\n",
       "      <td>Garces Taller Carrer ROCAFORT, 78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Taller Anton Solé</td>\n",
       "      <td>10</td>\n",
       "      <td>Plaça NAVAS</td>\n",
       "      <td>Taller Anton Solé Plaça NAVAS, 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Auto.Carburación</td>\n",
       "      <td>1</td>\n",
       "      <td>Carrer TEODOR BONAPLATA</td>\n",
       "      <td>Auto.Carburación Carrer TEODOR BONAPLATA, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M.F, Flomart</td>\n",
       "      <td>30</td>\n",
       "      <td>Passeig MONTJUIC</td>\n",
       "      <td>M.F, Flomart Passeig MONTJUIC, 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Talleres Espuña</td>\n",
       "      <td>68</td>\n",
       "      <td>Passeig MONTJUIC</td>\n",
       "      <td>Talleres Espuña Passeig MONTJUIC, 68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title number                   street  \\\n",
       "0      Garces Taller     78          Carrer ROCAFORT   \n",
       "1  Taller Anton Solé     10              Plaça NAVAS   \n",
       "2   Auto.Carburación      1  Carrer TEODOR BONAPLATA   \n",
       "3       M.F, Flomart     30         Passeig MONTJUIC   \n",
       "4    Talleres Espuña     68         Passeig MONTJUIC   \n",
       "\n",
       "                                       serch_o  \n",
       "0            Garces Taller Carrer ROCAFORT, 78  \n",
       "1            Taller Anton Solé Plaça NAVAS, 10  \n",
       "2  Auto.Carburación Carrer TEODOR BONAPLATA, 1  \n",
       "3            M.F, Flomart Passeig MONTJUIC, 30  \n",
       "4         Talleres Espuña Passeig MONTJUIC, 68  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ya se tiene construido nuestro elemento, lo siguiente será ir a buscar dicho elemento que se pasa por la herramienta de automatizadion ChromeDrive.  \n",
    "Los parametros que nos inteesarán son:  \n",
    "* full_name: El nombre completo del establecimiento, COMO SE ENCUENTRA EN EL SITIO DE GOOGLE MAPS.\n",
    "* rating: El rating de valoraciones (5-0).\n",
    "* total_ratings: El número de personas que han realizado una reseña\n",
    "* landmark_cat: La categoría del establecimiento,  SEGÚN LO CLASIFICA GOOGLE MAPS.\n",
    "* description: Descripción del establecimiento si la hay (normalmente no hay descripción).\n",
    "* address: La dirección del establecimiento, en la forma calle,avenida,placa,pasaje... + numero + codigo postal + ciudad\n",
    "* hours: Cuando esta disponible, se captura el horario de atención y su nivel de concurrencia. (puede variar en horario diario(04h-21h,05h-22h,06h-23h) y por dias abiertos todos los dias, cerrando sábado y domingo o solo domingo.\n",
    "* lat: SEGÚN GOOGLE latitud del establecimiento.\n",
    "* long: SEGÚN GOOGLE longitud del establecimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74dfe179b474bd4adfa1f19c1d64e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2. Extracting the data', max=30, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument('headless')\n",
    "\n",
    "browser = webdriver.Chrome(options=options)\n",
    "\n",
    "landmarks = df['serch_o']# PS.full_name+' '+PS.address\n",
    "\n",
    "\n",
    "# We want to remove any '/' character in the names and addresses in the landmarks list (because they'll break URLs) :\n",
    "landmarks = [i.replace('/', ' ') for i in landmarks]\n",
    "\n",
    "# These are the empty lists we will populate with the extracted data :\n",
    "full_name = []\n",
    "rating = []\n",
    "total_ratings = []\n",
    "landmark_cat = []\n",
    "description = []\n",
    "address = []\n",
    "hours = []\n",
    "lat = []\n",
    "long = []\n",
    "    \n",
    "# Here's the big loop iterating over the landmarks list :\n",
    "for landmark in tqdmn(landmarks, leave=False, desc='2. Extracting the data') :\n",
    "    \n",
    "    # URL making :\n",
    "    url = 'https://www.google.com/maps/search/' + landmark\n",
    "    browser.get(url)\n",
    "\n",
    "    # Waiting for the name of the landmark to load and be visible. If it fails, skip to next one :\n",
    "    try :\n",
    "        WebDriverWait(browser,30).until(EC.visibility_of_element_located((By.CLASS_NAME, \"section-hero-header-title-title\")))\n",
    "    except (NoSuchElementException, TimeoutException) as e :\n",
    "        continue\n",
    "        \n",
    "    # Extracting the data and putting it into the empty lists we defined earlier :\n",
    "    try:\n",
    "        full_name.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]').text)\n",
    "    except NoSuchElementException :\n",
    "        full_name.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        rating.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[2]/div/div[1]/span[1]/span/span').text)\n",
    "    except NoSuchElementException :\n",
    "        rating.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        total_ratings.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[2]/div/div[1]/span[2]/span/span[1]/span[2]/span[1]/button').text)\n",
    "    except NoSuchElementException:\n",
    "        total_ratings.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        landmark_cat.append(browser.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[2]/div/div[2]/span[1]/span[1]/button').text)\n",
    "    except NoSuchElementException:\n",
    "        landmark_cat.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        description.append(browser.find_element_by_css_selector('div[class=section-editorial-quote]').text)\n",
    "    except NoSuchElementException:\n",
    "        description.append(np.nan\n",
    "                          )\n",
    "    try:\n",
    "        address.append(browser.find_element_by_css_selector('div[data-tooltip=\"Copiar la dirección\"]').text)\n",
    "    except NoSuchElementException :\n",
    "        address.append(np.nan)\n",
    "\n",
    "    # Here we capture the popular hours for all 7 days starting with Sunday :\n",
    "    try:\n",
    "        hours.append([i.get_attribute('aria-label') for i in browser.find_elements_by_xpath(\"//*[contains(@aria-label, 'hora:')]\")])\n",
    "    except NoSuchElementException:\n",
    "        hours.append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        coordinates = browser.find_element_by_css_selector('meta[itemprop=image]').get_attribute('content')\n",
    "        coordinates = coordinates.split('?center=')[1].split('&zoom=')[0].split('%2C')\n",
    "        lat.append(coordinates[0])\n",
    "        long.append(coordinates[1])\n",
    "    except NoSuchElementException:\n",
    "        lat.append(np.nan)\n",
    "        long.append(np.nan)\n",
    "\n",
    "# Closing the Chrome window\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay mucha maneras de buscar los datos que nos interesan usando esta herramienta, se usa el fichero HTML buscando contenedores u objetos. Es importante tener un conocimiento minimo de HTML para realizar esta etapa. Sobre todo es para poder encontrar de manera especifica los parametros que nos interesan.  \n",
    "Ademas es de reconocer la potencia de esta herramienta pues se pueden definir diversos pasos para que automaticamente dadas algunas condiciones pueda capturar mas información navegando o escogiendo entre una lista de elementos al momento de realizar una busqueda.  \n",
    "Una perspectiva interesante para este proyecto seria guardar las reseñas que los usuarios ha dejado en cada comercio y realizar un analisis de NLP, solo por mencionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "HL = pd.DataFrame(data={'full_name':full_name, 'rating':rating, 'total_ratings':total_ratings, 'landmark_category':landmark_cat, 'description':description, 'address':address, 'hours':hours})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"t_dataRaw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se ordena como un DataFrame de Pandas, aunque lo que se vea de los primeros registros parezca poca información en realidad en cada regristro de la columna **hours** lo que se podria encontrar es algo como lo que se observa en imagen siguiente. Sin embargo toda esta informacion como se visualizará a continuación es informacion de la actividad del estableciento a cada hora durante cada dia de actividad. Esto quiere decir que si se tiene información de un establecimiento que esta abierto seis dias a la semana con un horario de 6 de la mañana a 23 horas toda esta informacion no representa, en el sentido practico, un dato que aporte al analisis. Por lo tanto desde la perspectiva del analista fue conveniente proponer que esta informacion se comprimiera de alguna manera haciendo la media de la actividad en el establecimiento. Lo anterior se podra observar con el transcurso de este Notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"t_colHour_dataRaw.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(list(HL[HL.full_name == 'MF Flomart'].hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_planner(place_name) :\n",
    "\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :'Sunday', \n",
    "    place_name = pd.DataFrame(index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "    #place_name = pd.DataFrame(index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],  \\\n",
    "                              columns=['06','07','08','09','10','11','12','13','14','15','16','17','18','19','20',\n",
    "                                       '21','22','23'])    \n",
    "    \n",
    "    # and then we return that dataframe\n",
    "    return place_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"empty_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada establecimiento se tendra que crear un tabla vacia con los dias de actividad y las horas activas. Lo anterior podrian ser de cinco a siete dias y siempre seran diez y ocho horas de actividad, lo que variaria en este caso serian los rangos de las horas de actvidad pudiendo comenzar mas temprano en algunos casos o mas tarde en otros. Por lo tanto aqui es donde reside la dificultad de este proceso, pues segun para cada caso que lo requiera el horario y los dias de atencion de cada establecieminto se deberia crear la tabla adecuada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = visit_planner(\"t_table\")\n",
    "\n",
    "# we need to remove the row for Sunday before proceeding\n",
    "table.drop('Saturday', axis=0, inplace=True)\n",
    "\n",
    "for hour in list(table):\n",
    "    table[hour] = re.findall('.{0,29}hora: '+str(hour)+'..', str(list(HL[HL.full_name=='MF Flomart'].hours)))\n",
    "    table[hour] = [ re.findall('\\d+', str(i))[0] for i in tall2[hour] ]\n",
    "    table[hour] = table[hour].astype(int)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(table, cmap='PuBu', linewidths=0.8, annot=True, annot_kws={'fontsize':8, 'alpha':0.8}, fmt='d', square=True,\n",
    "           cbar=False)\n",
    "\n",
    "plt.xticks(np.arange(18), list(tall2))\n",
    "plt.title(\"Popular times visiting MF Flomart\\n\", weight='semibold')\n",
    "\n",
    "# this bit of code ensures the heatmap will not show up truncated with some versions of matplotlib\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"filled_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo es correcto, uno podria encontrar una tabla rellenada como la se observa en la parte superior, y de manera grafica como se observa en la figura siguiente ( la tabla grafica solo es util para darse una idea de la dsitribucion a lo largo de una semana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"show_ftable.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de esto es conseguir de la tabla anterior, la tabla rellenada con los valores de cada hora, una tabla **.describe()**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"describe_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y aún cuando ya se tuviera lo anterior, la idea final escomprimir esta informacion haciendo la media de la anterior tabla:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"reduced_described_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aqui se ha explicado como se obtuvieron los datos de cada consulta que se realizdo en google Maps de cada registro en los datos que tenia Eixos. Ademas se ha explicado un poco de la idea que se tiene para enriquecer mas cada registro de este dataset que se obtuvo de google haciendo uso de la columna hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAR MAS INFORMACIÓN A PARTIR DE LA COLUMNA HOURS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta esta parte del proceso se asume que ya se tiene toda la informacion que se puedo obtener de las consultas realizadas a Google maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['hfull_stcl_ldmks_attem19798_succ6095.csv',\n",
    "             'hfull_stcl_ldmks_attem33872_succ10300.csv',\n",
    "             'hfull_stcl_ldmks_attem35886_succ1033.csv',\n",
    "             'hfull_stcl_ldmks_attem36514_succ424.csv',\n",
    "             'hfull_stcl_ldmks_attem38201_succ559.csv',\n",
    "             'hfull_stcl_ldmks_attem38849_succ287.csv',\n",
    "             'hfull_stcl_ldmks_attem39701_succ256.csv',\n",
    "             'hfull_stcl_ldmks_attem41723_succ662.csv',\n",
    "             'hfull_stcl_ldmks_attem45541_succ917.csv',\n",
    "             'hfull_stcl_ldmks_attem47051_succ623.csv',\n",
    "             'hfull_stcl_ldmks_attem50323_succ1553.csv',\n",
    "             'hfull_stcl_ldmks_attem50969_succ240.csv',\n",
    "             'hfull_stcl_ldmks_attem51465_succ151.csv',\n",
    "             'hfull_stcl_ldmks_attem53551_succ706.csv',\n",
    "             'hfull_stcl_ldmks_attem59786_succ1368.csv',\n",
    "             'hfull_stcl_ldmks_attem63950_succ1057.csv',\n",
    "             'hfull_stcl_ldmks_attem65546_succ463.csv',\n",
    "             'hfull_stcl_ldmks_attem69434_succ503.csv',\n",
    "             'hfull_stcl_ldmks_attem69894_succ176.csv']\n",
    "list_data = []\n",
    "  \n",
    "# Escribimos un loop que irá a través de cada uno de los nombres de archivo a través de globbing y el resultado final será la lista dataframes\n",
    "\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "\n",
    "df_concat = pd.concat(list_data,ignore_index=True)\n",
    "df_concat = df_concat.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21526, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ve anteriormente los registros unicos son 21526, aunque los que se obtuvieron fueron aproximadamente 22mil y un poco mas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego al tener listo en un solo DataFrame todos los regitros se crea una nueva tabla vacia donde se guardara la informacion que se generara por cada registros que cumpla con las condiciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = pd.DataFrame(index = df_concat.index.values, \\\n",
    "                       columns=('count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente funcion lo que se hace es declarar tablas para los cuatro casos de horarios que se considerarán:\n",
    "* de 24h a 17h\n",
    "* de 04h a 21h\n",
    "* de 05h a 22h\n",
    "* de 06h a 23h  \n",
    "Todas la tablas asumiran al inicio que si se invocan se crearan con los siete dias y si se tiene que eliminar un dia asi se hará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_planner0_17(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['24','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17'])    \n",
    "    return place_name\n",
    "\n",
    "def visit_planner4_21(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21'])    \n",
    "    return place_name\n",
    "\n",
    "def visit_planner5_22(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22'])    \n",
    "    return place_name\n",
    "\n",
    "\n",
    "def visit_planner6_23(place_name) :\n",
    "    # first we make an empty dataframe out of a list of days as index and a list of hours as columns :\n",
    "    place_name = pd.DataFrame(index=['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'], \\\n",
    "                              columns=['06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23'])    \n",
    "    return place_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supZeros(chnk):\n",
    "    line = str(list(df_concat[df_concat.index == chnk].hours))\n",
    "    df_concat['hours'][chnk] = re.sub('\\:00\\)', ')', line)[2:-2]\n",
    "    \n",
    "    #lsd = []\n",
    "    #sd = str(df_concat['hours'][chnk]).split(',')\n",
    "    #for i in sd:\n",
    "    #        if bool(re.findall('\\:00\\)', i)) == True:\n",
    "    #            lsd.append(sd.index(i))\n",
    "    #sd = np.delete(sd,lsd)\n",
    "    #df_concat['hours'][chnk] = sd[2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chgTtbyFi(chnk):\n",
    "    lsd = []\n",
    "    sd = str(df_concat['hours'][chnk]).split(',')\n",
    "    for i in sd:\n",
    "            if bool(re.findall('\\: 23\\)', i)) == True:\n",
    "                sd[sd.index(i)] = ' Nivel de ocupación:  0\\\\xa0% (hora: 05).' \n",
    "                print(i, chnk)\n",
    "    df_concat['hours'][chnk] = sd[2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambioValSpl(chnk):\n",
    "        sd = str(df_concat['hours'][chnk]).split(',')\n",
    "        lst = []\n",
    "        lsd = []\n",
    "        for i in sd:\n",
    "            lst.append(len(i))\n",
    "            if len(i) < 40:\n",
    "                lsd.append(sd.index(i))\n",
    "        posMax = lst.index(max(lst))\n",
    "        sd = str(df_concat['hours'][chnk]).split(',')\n",
    "        lst=[]\n",
    "        i = str(re.findall('.{0,10}habitual.{0,11}', str(list(df_concat[df_concat.index==chnk].hours))))[2:-2]\n",
    "        ii = int(re.findall('\\d+',i)[0])\n",
    "        isw = int(re.findall('\\d+',sd[posMax-1])[2])+1\n",
    "        #'Nivel de ocupación: 29\\\\xa0% (hora: 16).'\n",
    "        if isw < 10:\n",
    "            sd[posMax] = ' \\'Nivel de ocupación: '+str(ii)+'\\\\xa0% (hora: 0'+ str(isw) +').'\n",
    "        else: \n",
    "            sd[posMax] = ' \\'Nivel de ocupación: '+str(ii)+'\\\\xa0% (hora: '+ str(isw) +').'\n",
    "        sd = np.delete(sd,lsd)\n",
    "        df_concat['hours'][chnk] = sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alter\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dfConcat_inx = df_concat.index.values\n",
    "for i in dfConcat_inx:\n",
    "    if bool(re.search(\"habitual.\",str(list(df_concat[df_concat.index == i].hours)))) == True:\n",
    "        cambioValSpl(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alter\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dfConcat_inx = df_concat.index.values\n",
    "for i in dfConcat_inx:\n",
    "    \n",
    "    if bool(re.search(\"\\:00\",str(list(df_concat[df_concat.index == i].hours)))) == True:\n",
    "        supZeros(i)\n",
    "    #if bool(re.search(\"habitual.\",str(list(df_concat[df_concat.index == i].hours)))) == True:\n",
    "        #supZeros(i)\n",
    "    \n",
    "    #if (len(re.findall(\"\\(hora\\: 23\\)\",str(list(df_concat[df_concat.index == i].hours)))) == 1 and \\\n",
    "    #    len(re.findall(\"\\(hora\\: 05\\)\",str(list(df_concat[df_concat.index == i].hours)))) == 5):\n",
    "    #    print(i,'enviado...')\n",
    "    #    chgTtbyFi(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5470"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HL_inx = df_concat.index.values\n",
    "cntPer= df_concat.hours.apply(lambda x: len(str(x).split(',')))\n",
    "#cntPer = df_concat.hours.apply(lambda x: len(x.split(',')))\n",
    "arrInf = np.column_stack((HL_inx,cntPer))\n",
    "vac = []\n",
    "iver = []\n",
    "#sev = False\n",
    "\n",
    "# visit_plannerD visit_plannerC visit_plannerS\n",
    "\n",
    "\n",
    "for (i, j) in arrInf:\n",
    "    if j >= 90:\n",
    "        \n",
    "        sev = False\n",
    "        six = False\n",
    "        fiv = False\n",
    "        \n",
    "        #SIETE DIAS\n",
    "        if (len(re.findall('.{0,36}04'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}21'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 ):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner4_21(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1] \n",
    "            sev = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and sev == False):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner5_22(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1] \n",
    "            sev = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}23'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and sev == False):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner6_23(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]   \n",
    "            sev = True\n",
    "                    \n",
    "        if (len(re.findall('.{0,36}24'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}03'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \\\n",
    "            len(re.findall('.{0,36}17'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and \n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 7 and sev == False):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner0_17(\"temp_table\")\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]           \n",
    "            sev = True\n",
    "            \n",
    "        #SEIS DIAS            \n",
    "        if (len(re.findall('.{0,36}04'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}21'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False ):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner4_21(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "\n",
    "        if (len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False and six == False ):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            \n",
    "            t_table = visit_planner5_22(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}23'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False and six == False ):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            \n",
    "            t_table = visit_planner6_23(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}24'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}03'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}17'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 6 and sev == False and six == False ):\n",
    "            #print(i, j,'tabla de seis dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner0_17(\"temp_table\")\n",
    "            t_table.drop('Sunday', axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            \n",
    "            six = True\n",
    "            \n",
    "        #CINCO DIAS\n",
    "        if (len(re.findall('.{0,36}04'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}21'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False):\n",
    "            #print(i, j,'tabla de seis dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner4_21(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            fiv = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False and fiv == False):\n",
    "            #print(i, j,'tabla de cinco dias de 05 a 10')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner5_22(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            fiv = True\n",
    "            \n",
    "        if (len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}23'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False and fiv == False):\n",
    "            #print(i, j,'tabla de cinco dias de 06 a 11')\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner6_23(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "            fiv = True\n",
    "        if (len(re.findall('.{0,36}24'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}03'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}17'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}05'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}06'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and \\\n",
    "            len(re.findall('.{0,36}07'+'\\)', str(list(df_concat[df_concat.index == i].hours))))== 5 and sev == False and six == False and fiv == False):\n",
    "            vac.append(i)\n",
    "            t_table = visit_planner0_17(\"temp_table\")\n",
    "            t_table.drop(['Sunday','Saturday'], axis=0, inplace=True)\n",
    "            for hour in list(t_table):\n",
    "                \n",
    "                t_table[hour] = re.findall('.{0,36}'+hour+'\\)', str(list(df_concat[df_concat.index == i].hours)))\n",
    "                t_table[hour] = [ re.findall('\\d+', str(j))[0] for j in t_table[hour] ]\n",
    "                t_table[hour] = t_table[hour].astype(int)\n",
    "            table_des = pd.DataFrame()\n",
    "            table_des = pd.DataFrame((t_table.describe()[:]).mean(axis=1)).T\n",
    "            comp_df.iloc[i] = table_des.iloc[-1]\n",
    "        if(fiv == True or six == True or sev == True):\n",
    "            iver.append(i)\n",
    "len(vac)\n",
    "        #bool(re.findall('\\: 23|\\: 00|\\: 01|\\: 02|\\(hora\\:\\ \\)', i)) == True:\n",
    "        #re.findall('.{0,36}22'+'\\)', str(list(df_concat[df_concat.index == 3227].hours)))\n",
    "        #for hour in list(t_table):\n",
    "         #    re.findall('.{0,36}'+hour+'\\)', str(list(HL[HL.index == position].hours)))\n",
    "         #   [ re.findall('\\d+', str(i))[0] for i in t_table[hour] ]\n",
    "         #   t_table[hour].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>18.9444</td>\n",
       "      <td>8.10061</td>\n",
       "      <td>10.5556</td>\n",
       "      <td>14.1667</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21.9444</td>\n",
       "      <td>30.5556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21526 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count     mean      std      min      25%   50%      75%      max\n",
       "0       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "1       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "2       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "3         5  18.9444  8.10061  10.5556  14.1667  17.5  21.9444  30.5556\n",
       "4       NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "...     ...      ...      ...      ...      ...   ...      ...      ...\n",
       "21521   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21522   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21523   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21524   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "21525   NaN      NaN      NaN      NaN      NaN   NaN      NaN      NaN\n",
       "\n",
       "[21526 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_ratings</th>\n",
       "      <th>landmark_category</th>\n",
       "      <th>description</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>hours</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Tallers Garcés</td>\n",
       "      <td>4,1</td>\n",
       "      <td>(10)</td>\n",
       "      <td>Taller de automóviles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Rocafort, 78, 08015 Barcelona</td>\n",
       "      <td>934 23 10 93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.379371</td>\n",
       "      <td>2.153754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Taller Antón Solé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plaça de las Navas, 10, 08004 Barcelona</td>\n",
       "      <td>934 23 45 63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.374035</td>\n",
       "      <td>2.158775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Auto Carburacion e Inyeccion</td>\n",
       "      <td>5,0</td>\n",
       "      <td>(2)</td>\n",
       "      <td>Taller de reparación de vehículos todoterreno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C/ d'Entença, 20, 08015 Barcelona</td>\n",
       "      <td>933 25 46 94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.376014</td>\n",
       "      <td>2.155615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MF Flomart</td>\n",
       "      <td>4,9</td>\n",
       "      <td>(35)</td>\n",
       "      <td>Tienda de repuestos para automóviles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passeig de Montjuïc, 30, 08004 Barcelona</td>\n",
       "      <td>934 41 13 48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Nivel de ocupación: \\xa0% (hora: ).', 'Nivel...</td>\n",
       "      <td>41.372421</td>\n",
       "      <td>2.171510</td>\n",
       "      <td>5</td>\n",
       "      <td>18.9444</td>\n",
       "      <td>8.10061</td>\n",
       "      <td>10.5556</td>\n",
       "      <td>14.1667</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21.9444</td>\n",
       "      <td>30.5556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Talleres Espuña</td>\n",
       "      <td>4,6</td>\n",
       "      <td>(10)</td>\n",
       "      <td>Taller de reparación de automóviles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passeig de Montjuïc, 68, 08004 Barcelona</td>\n",
       "      <td>934 41 48 10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.371756</td>\n",
       "      <td>2.167712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21521</td>\n",
       "      <td>De Pata Negra</td>\n",
       "      <td>3,7</td>\n",
       "      <td>(264)</td>\n",
       "      <td>Bar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plaça de las Navas, 7, 08004 Barcelona, España</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m.facebook.com</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.373856</td>\n",
       "      <td>2.159229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21522</td>\n",
       "      <td>Malabida</td>\n",
       "      <td>4,5</td>\n",
       "      <td>(171)</td>\n",
       "      <td>Bar restaurante</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Blai, 63, 08004 Barcelona, España</td>\n",
       "      <td>+34 931 75 81 79</td>\n",
       "      <td>malabida.business.site</td>\n",
       "      <td>['Nivel de ocupación: 0\\\\xa0% (hora: 04).', 'N...</td>\n",
       "      <td>41.374590</td>\n",
       "      <td>2.161894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21523</td>\n",
       "      <td>Bodega 1900</td>\n",
       "      <td>4,4</td>\n",
       "      <td>(990)</td>\n",
       "      <td>Bar de tapas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Tamarit, 91, 08015 Barcelona, España</td>\n",
       "      <td>+34 933 25 26 59</td>\n",
       "      <td>elbarri.com</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.375552</td>\n",
       "      <td>2.156562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21524</td>\n",
       "      <td>Vinoteca San Antoni By Wine Palace</td>\n",
       "      <td>4,5</td>\n",
       "      <td>(68)</td>\n",
       "      <td>Bodega</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer del Comte Borrell, 30, 08015 Barcelona,...</td>\n",
       "      <td>+34 935 39 40 02</td>\n",
       "      <td>winepalace.es</td>\n",
       "      <td>['Nivel de ocupación: \\\\xa0% (hora: ).', 'Nive...</td>\n",
       "      <td>41.376737</td>\n",
       "      <td>2.163638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21525</td>\n",
       "      <td>Bodega Xavier Can Anxoves</td>\n",
       "      <td>5,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrer de Vallhonrat, 18, 08004 Barcelona, España</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>41.374166</td>\n",
       "      <td>2.156982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21526 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                full_name rating total_ratings  \\\n",
       "0                          Tallers Garcés    4,1          (10)   \n",
       "1                       Taller Antón Solé    NaN           NaN   \n",
       "2            Auto Carburacion e Inyeccion    5,0           (2)   \n",
       "3                              MF Flomart    4,9          (35)   \n",
       "4                         Talleres Espuña    4,6          (10)   \n",
       "...                                   ...    ...           ...   \n",
       "21521                       De Pata Negra    3,7         (264)   \n",
       "21522                            Malabida    4,5         (171)   \n",
       "21523                         Bodega 1900    4,4         (990)   \n",
       "21524  Vinoteca San Antoni By Wine Palace    4,5          (68)   \n",
       "21525           Bodega Xavier Can Anxoves    5,0           NaN   \n",
       "\n",
       "                                   landmark_category description  \\\n",
       "0                              Taller de automóviles         NaN   \n",
       "1                                                NaN         NaN   \n",
       "2      Taller de reparación de vehículos todoterreno         NaN   \n",
       "3               Tienda de repuestos para automóviles         NaN   \n",
       "4                Taller de reparación de automóviles         NaN   \n",
       "...                                              ...         ...   \n",
       "21521                                            Bar         NaN   \n",
       "21522                                Bar restaurante         NaN   \n",
       "21523                                   Bar de tapas         NaN   \n",
       "21524                                         Bodega         NaN   \n",
       "21525                                            NaN         NaN   \n",
       "\n",
       "                                                 address             phone  \\\n",
       "0                Carrer de Rocafort, 78, 08015 Barcelona      934 23 10 93   \n",
       "1                Plaça de las Navas, 10, 08004 Barcelona      934 23 45 63   \n",
       "2                      C/ d'Entença, 20, 08015 Barcelona      933 25 46 94   \n",
       "3               Passeig de Montjuïc, 30, 08004 Barcelona      934 41 13 48   \n",
       "4               Passeig de Montjuïc, 68, 08004 Barcelona      934 41 48 10   \n",
       "...                                                  ...               ...   \n",
       "21521     Plaça de las Navas, 7, 08004 Barcelona, España               NaN   \n",
       "21522        Carrer de Blai, 63, 08004 Barcelona, España  +34 931 75 81 79   \n",
       "21523     Carrer de Tamarit, 91, 08015 Barcelona, España  +34 933 25 26 59   \n",
       "21524  Carrer del Comte Borrell, 30, 08015 Barcelona,...  +34 935 39 40 02   \n",
       "21525  Carrer de Vallhonrat, 18, 08004 Barcelona, España               NaN   \n",
       "\n",
       "                      website  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "...                       ...   \n",
       "21521          m.facebook.com   \n",
       "21522  malabida.business.site   \n",
       "21523             elbarri.com   \n",
       "21524           winepalace.es   \n",
       "21525                     NaN   \n",
       "\n",
       "                                                   hours   latitude  \\\n",
       "0                                                     []  41.379371   \n",
       "1                                                     []  41.374035   \n",
       "2                                                     []  41.376014   \n",
       "3      ['Nivel de ocupación: \\xa0% (hora: ).', 'Nivel...  41.372421   \n",
       "4                                                     []  41.371756   \n",
       "...                                                  ...        ...   \n",
       "21521                                                 []  41.373856   \n",
       "21522  ['Nivel de ocupación: 0\\\\xa0% (hora: 04).', 'N...  41.374590   \n",
       "21523                                                 []  41.375552   \n",
       "21524  ['Nivel de ocupación: \\\\xa0% (hora: ).', 'Nive...  41.376737   \n",
       "21525                                                 []  41.374166   \n",
       "\n",
       "       longitude count     mean      std      min      25%   50%      75%  \\\n",
       "0       2.153754   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "1       2.158775   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "2       2.155615   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "3       2.171510     5  18.9444  8.10061  10.5556  14.1667  17.5  21.9444   \n",
       "4       2.167712   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "...          ...   ...      ...      ...      ...      ...   ...      ...   \n",
       "21521   2.159229   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21522   2.161894   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21523   2.156562   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21524   2.163638   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "21525   2.156982   NaN      NaN      NaN      NaN      NaN   NaN      NaN   \n",
       "\n",
       "           max  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3      30.5556  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "21521      NaN  \n",
       "21522      NaN  \n",
       "21523      NaN  \n",
       "21524      NaN  \n",
       "21525      NaN  \n",
       "\n",
       "[21526 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_GoogleMaps = pd.merge(df_concat, comp_df, left_index=True, right_index=True, how='outer')\n",
    "final_GoogleMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_GoogleMaps.to_csv('table_of_MEANS_googleData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
